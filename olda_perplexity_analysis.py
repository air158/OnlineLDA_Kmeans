import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import LatentDirichletAllocation
from scipy.sparse import lil_matrix
import warnings
import time
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

print("="*70)
print("åœ¨çº¿LDA (Online LDA) å›°æƒ‘åº¦åˆ†æ")
print("="*70)

# è¯»å–æ•°æ®
print("\n[1/5] æ­£åœ¨è¯»å–æ•°æ®...")
start_time = time.time()
df = pd.read_csv('cn_bow.csv')
print(f"âœ“ æ•°æ®è¯»å–å®Œæˆ ({time.time()-start_time:.2f}ç§’)")

# è§£æbow_vectoråˆ—
print("\n[2/5] æ­£åœ¨è§£æè¯è¢‹å‘é‡...")
start_time = time.time()

def parse_bow_vector(bow_string):
    """å°† 'è¯ID:é¢‘æ¬¡ è¯ID:é¢‘æ¬¡' æ ¼å¼è½¬æ¢ä¸ºå­—å…¸"""
    bow_dict = {}
    for item in bow_string.split():
        word_id, count = item.split(':')
        bow_dict[int(word_id)] = int(count)
    return bow_dict

# è·å–æ‰€æœ‰è¯ID
all_word_ids = set()
bow_vectors = []
for bow_str in df['bow_vector']:
    bow_dict = parse_bow_vector(bow_str)
    bow_vectors.append(bow_dict)
    all_word_ids.update(bow_dict.keys())

# åˆ›å»ºè¯IDåˆ°åˆ—ç´¢å¼•çš„æ˜ å°„
word_id_to_idx = {word_id: idx for idx, word_id in enumerate(sorted(all_word_ids))}
n_features = len(all_word_ids)

print(f"âœ“ è§£æå®Œæˆ ({time.time()-start_time:.2f}ç§’)")
print(f"  - æ–‡æ¡£æ•°é‡: {len(bow_vectors):,}")
print(f"  - è¯æ±‡è¡¨å¤§å°: {n_features:,}")

# æ„å»ºç¨€ç–çŸ©é˜µ
print("\n[3/5] æ­£åœ¨æ„å»ºç¨€ç–çŸ©é˜µ...")
start_time = time.time()
X = lil_matrix((len(bow_vectors), n_features), dtype=np.float32)
for i, bow_dict in enumerate(bow_vectors):
    for word_id, count in bow_dict.items():
        X[i, word_id_to_idx[word_id]] = count

# è½¬æ¢ä¸ºcsræ ¼å¼ä»¥æé«˜è®¡ç®—æ•ˆç‡
X = X.tocsr()
sparsity = 1 - X.nnz / (X.shape[0] * X.shape[1])
print(f"âœ“ çŸ©é˜µæ„å»ºå®Œæˆ ({time.time()-start_time:.2f}ç§’)")
print(f"  - çŸ©é˜µå½¢çŠ¶: {X.shape}")
print(f"  - ç¨€ç–åº¦: {sparsity:.2%}")
print(f"  - éé›¶å…ƒç´ : {X.nnz:,}")

# è®¾ç½®è¦æµ‹è¯•çš„ä¸»é¢˜æ•°é‡èŒƒå›´
topic_range = list(range(2, 21, 2))  # 2, 4, 6, 8, ..., 20
perplexities = []
exp_neg_log_perplexities = []

print(f"\n[4/5] å¼€å§‹åœ¨çº¿LDAè®­ç»ƒï¼ˆå…±{len(topic_range)}ä¸ªä¸»é¢˜æ•°ï¼‰...")
print("="*70)

total_start = time.time()
for idx, n_topics in enumerate(topic_range, 1):
    iter_start = time.time()
    print(f"\n[{idx}/{len(topic_range)}] ä¸»é¢˜æ•° = {n_topics}")

    # ä½¿ç”¨åœ¨çº¿LDA (Online LDA)
    olda = LatentDirichletAllocation(
        n_components=n_topics,
        max_iter=10,                    # å‡å°‘è¿­ä»£æ¬¡æ•°
        learning_method='online',       # åœ¨çº¿å­¦ä¹ æ–¹æ³•
        learning_decay=0.7,             # å­¦ä¹ ç‡è¡°å‡
        learning_offset=50.0,           # å­¦ä¹ ç‡åç§»
        batch_size=512,                 # æ‰¹æ¬¡å¤§å°
        random_state=42,
        n_jobs=1,                       # å•çº¿ç¨‹é¿å…å†…å­˜é—®é¢˜
        verbose=0
    )

    # è®­ç»ƒæ¨¡å‹
    print("  - è®­ç»ƒä¸­...", end=" ", flush=True)
    olda.fit(X)

    # è®¡ç®—å›°æƒ‘åº¦
    perplexity = olda.perplexity(X)
    perplexities.append(perplexity)

    # è®¡ç®— e^(-log(perplexity)) = 1/perplexity
    exp_neg_log_perplexity = np.exp(-np.log(perplexity))
    exp_neg_log_perplexities.append(exp_neg_log_perplexity)

    elapsed = time.time() - iter_start
    print(f"å®Œæˆ ({elapsed:.1f}ç§’)")
    print(f"  - å›°æƒ‘åº¦: {perplexity:.2f}")
    print(f"  - e^(-log(Perplexity)): {exp_neg_log_perplexity:.6f}")

total_time = time.time() - total_start
print("\n" + "="*70)
print(f"âœ“ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’ (å¹³å‡ {total_time/len(topic_range):.1f}ç§’/æ¨¡å‹)")

# åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
print("\n[5/5] æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# å­å›¾1: å›°æƒ‘åº¦æ›²çº¿
axes[0].plot(topic_range, perplexities, 'bo-', linewidth=2.5, markersize=8,
             markerfacecolor='lightblue', markeredgewidth=2)
axes[0].set_xlabel('ä¸»é¢˜ä¸ªæ•°', fontsize=13, fontweight='bold')
axes[0].set_ylabel('å›°æƒ‘åº¦ (Perplexity)', fontsize=13, fontweight='bold')
axes[0].set_title('åœ¨çº¿LDAæ¨¡å‹å›°æƒ‘åº¦ä¸ä¸»é¢˜ä¸ªæ•°çš„å…³ç³»', fontsize=14, fontweight='bold', pad=15)
axes[0].grid(True, alpha=0.3, linestyle='--', linewidth=1)
axes[0].set_xticks(topic_range)
axes[0].tick_params(labelsize=11)

# æ ‡æ³¨æœ€å°å€¼
min_idx = np.argmin(perplexities)
axes[0].scatter([topic_range[min_idx]], [perplexities[min_idx]],
                color='red', s=200, zorder=5, marker='*',
                edgecolors='darkred', linewidths=2)
axes[0].annotate(f'æœ€å°å€¼\nä¸»é¢˜æ•°={topic_range[min_idx]}\nå›°æƒ‘åº¦={perplexities[min_idx]:.2f}',
                xy=(topic_range[min_idx], perplexities[min_idx]),
                xytext=(10, 20), textcoords='offset points',
                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='red'),
                fontsize=10, fontweight='bold')

# å­å›¾2: eçš„è´Ÿå¯¹æ•°æ¬¡æ–¹æ›²çº¿
axes[1].plot(topic_range, exp_neg_log_perplexities, 'ro-', linewidth=2.5,
             markersize=8, markerfacecolor='lightcoral', markeredgewidth=2)
axes[1].set_xlabel('ä¸»é¢˜ä¸ªæ•°', fontsize=13, fontweight='bold')
axes[1].set_ylabel('e^(-log(Perplexity))', fontsize=13, fontweight='bold')
axes[1].set_title('eçš„è´Ÿå¯¹æ•°å›°æƒ‘åº¦ä¸ä¸»é¢˜ä¸ªæ•°çš„å…³ç³»', fontsize=14, fontweight='bold', pad=15)
axes[1].grid(True, alpha=0.3, linestyle='--', linewidth=1)
axes[1].set_xticks(topic_range)
axes[1].tick_params(labelsize=11)

# æ ‡æ³¨æœ€å¤§å€¼
max_idx = np.argmax(exp_neg_log_perplexities)
axes[1].scatter([topic_range[max_idx]], [exp_neg_log_perplexities[max_idx]],
                color='darkgreen', s=200, zorder=5, marker='*',
                edgecolors='green', linewidths=2)
axes[1].annotate(f'æœ€å¤§å€¼\nä¸»é¢˜æ•°={topic_range[max_idx]}\nå€¼={exp_neg_log_perplexities[max_idx]:.6f}',
                xy=(topic_range[max_idx], exp_neg_log_perplexities[max_idx]),
                xytext=(10, -30), textcoords='offset points',
                bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.7),
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='green'),
                fontsize=10, fontweight='bold')

plt.tight_layout()
plt.savefig('olda_perplexity_analysis.png', dpi=300, bbox_inches='tight')
print("âœ“ å›¾è¡¨å·²ä¿å­˜ä¸º 'olda_perplexity_analysis.png'")

# ä¿å­˜ç»“æœ
results_df = pd.DataFrame({
    'ä¸»é¢˜ä¸ªæ•°': topic_range,
    'å›°æƒ‘åº¦': perplexities,
    'e^(-log(Perplexity))': exp_neg_log_perplexities
})

print("\n" + "="*70)
print("è¯¦ç»†ç»“æœ:")
print("="*70)
print(results_df.to_string(index=False))
print("="*70)

results_df.to_csv('olda_perplexity_results.csv', index=False, encoding='utf-8-sig')
print("\nâœ“ ç»“æœå·²ä¿å­˜ä¸º 'olda_perplexity_results.csv'")

# åˆ†ææœ€ä¼˜ä¸»é¢˜æ•°
optimal_idx = np.argmin(perplexities)
optimal_topics = topic_range[optimal_idx]

print("\n" + "="*70)
print("æœ€ä¼˜ä¸»é¢˜æ•°åˆ†æ:")
print("="*70)
print(f"ğŸ“Š æœ€ä¼˜ä¸»é¢˜ä¸ªæ•°ï¼ˆå›°æƒ‘åº¦æœ€ä½ï¼‰: {optimal_topics}")
print(f"ğŸ“‰ å¯¹åº”å›°æƒ‘åº¦: {perplexities[optimal_idx]:.2f}")
print(f"ğŸ“ˆ å¯¹åº” e^(-log(Perplexity)): {exp_neg_log_perplexities[optimal_idx]:.6f}")
print("="*70)

print("\nâœ… åˆ†æå®Œæˆï¼")
plt.show()
